{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJkbJE1DeSbrSSs2Ih1VtW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SakchaiSaehoei/China-Scholarship-Web-Scriping/blob/main/scholarship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# day 1\n",
        "extract data form the website\n",
        "# day 2\n",
        "For mat data and write them into csv"
      ],
      "metadata": {
        "id": "Ybc4DuHso539"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "import bs4\n",
        "import io\n",
        "import time\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hmQiYS3CaxG2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(url):\n",
        "    r = requests.get(url) #returns the HTML of the page, can be done through urlopen as well\n",
        "    soup = bs4.BeautifulSoup(r.content)\n",
        "\n",
        "    all_td = soup.findAll(\"td\")\n",
        "    # 0 : titles 1 : language 2: Start 3 : scholarship 4: to_pay\n",
        "\n",
        "    universities = []\n",
        "    universities_logo = []\n",
        "    titles = all_td[0:len(all_td):6]\n",
        "    languages = all_td[1:len(all_td):6]\n",
        "    start = all_td[2:len(all_td):6]\n",
        "    scholarship = all_td[3:len(all_td):6]\n",
        "    to_pay = all_td[4:len(all_td):6]\n",
        "\n",
        "    # print(titles[0].find_all('a')[0]['href'])\n",
        "    for idx, link in  enumerate(titles) :\n",
        "      href = titles[idx].find_all('a')[0]['href']\n",
        "      fullLink = \"https://www.cucas.cn/\" + href\n",
        "      program_info_url = requests.get(fullLink) #returns the HTML of the page, can be done through urlopen as well\n",
        "      program_info = bs4.BeautifulSoup(program_info_url.content)\n",
        "      university_name = program_info.find('h4').text\n",
        "      universities.append(university_name)\n",
        "      university_logo = program_info.find('div',{\"class\": \"img\"})\n",
        "      university_logo_url =   \"https://www.cucas.cn/\" + university_logo('img')[0]['src']\n",
        "      universities_logo.append(university_logo_url)\n",
        "      # print(university_logo_url)\n",
        "    return titles, languages, start, scholarship, to_pay , universities , university_logo_url"
      ],
      "metadata": {
        "id": "Ts5Nq_7RazV0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def page_count(url):\n",
        "    url = url + str(1)\n",
        "    r = requests.get(url) #returns the HTML of the page, can be done through urlopen as well\n",
        "    soup = bs4.BeautifulSoup(r.content)\n",
        "    # print(soup)\n",
        "    page_numbers = soup.findAll(\"ul\",{\"class\":\"paginator\"})\n",
        "    total_schols = int(page_numbers[0].text[page_numbers[0].text.find(':')+1:])\n",
        "    if (total_schols%20==0):\n",
        "        iterations = total_schols/20\n",
        "    else:\n",
        "        iterations = int(total_schols/20)+1\n",
        "    return(int(iterations))"
      ],
      "metadata": {
        "id": "c3BriL4-a4QC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "dict = {}\n",
        "program_id=1\n",
        "with open('test_new.csv', 'w', newline='',encoding=\"utf-8\") as fp:\n",
        "    a = csv.writer(fp, delimiter=',')\n",
        "    a.writerows([['Program ID','University','Program','Level','Language','Start Date','Tuition Covered', 'Accomodation covered?', 'Living Expense Covered?','Tuition fees to pay','Original Tuition fee','Accomodation to pay','Living expense to pay', 'School Logo']])\n",
        "    majors = ['non_degree','bachelor_degree','master_degree','doctor_degree','undefined']\n",
        "    levels = ['Associate','Bachelor','Master','Phd','Non-Degree']\n",
        "\n",
        "    for id , major in enumerate(majors):\n",
        "        url = 'https://www.cucas.cn/china_scholarships/index/all_scholarship/all_cities/all_universities/' + str(major) + '/all_languages/all_year/all_programs/0_0_0_0_' + str(id+1) + '_0_0/page='\n",
        "        iterations = page_count(url)\n",
        "        level = levels[id]\n",
        "        # loop for extract information in each page\n",
        "\n",
        "        for page in range(1,iterations+1):\n",
        "            url_new = url + str(page)\n",
        "            # print(url_new)\n",
        "            titles, languages, start, scholarship, to_pay, universities, universities_logo = extract(url_new)\n",
        "            # print(titles)\n",
        "          # The result of titles, languages...... are bs4.element.Tag in side the list of all titles in the page\n",
        "            # loop for get into each list and write into the csv file \"a\" row by row\n",
        "            \"\"\"handel : scholarship into tutuition, accomodation , living expense \"\"\"\n",
        "            for i in range(0,len(titles)):\n",
        "              program = titles[i].text\n",
        "              language = languages[i].text\n",
        "              start_date = start[i].text\n",
        "              uinversity = universities[i]\n",
        "\n",
        "              tuition_acc_living = scholarship[i].p.text\n",
        "              tuition = tuition_acc_living[tuition_acc_living.find(':')+1:tuition_acc_living.find('\\n')].strip()\n",
        "\n",
        "              accomodation = tuition_acc_living[tuition_acc_living.find(':',tuition_acc_living.find('Accom'))+1:tuition_acc_living.find('\\n',tuition_acc_living.find('Accom'))].strip()\n",
        "\n",
        "              living = tuition_acc_living[tuition_acc_living.find(':',tuition_acc_living.find('Living'))+1:].strip()\n",
        "\n",
        "              To_Pay = to_pay[i].p.text\n",
        "              try:\n",
        "                   orig_tuition = to_pay[i].p.span.text.strip()\n",
        "              except:\n",
        "                  orig_tuition=-1\n",
        "              try:\n",
        "                  tuition_to_pay = To_Pay[To_Pay.find(':')+1:To_Pay.find('\\n',To_Pay.find(':')+1)].strip().replace(orig_tuition,'').strip()\n",
        "              except:\n",
        "                  tuition_to_pay = To_Pay[To_Pay.find(':')+1:To_Pay.find('\\n', To_Pay.find(':'))].strip()\n",
        "              try:\n",
        "                  accomodation_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Acco'))+1:To_Pay.find('\\n',To_Pay.find(':',To_Pay.find('Acco')))].strip()\n",
        "              except:\n",
        "                   accomodation_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Acc'))+1:To_Pay.find('\\n',To_Pay.find('Acc'))].strip()\n",
        "              try:\n",
        "                   Living_Expense_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Expense'))+1:To_Pay.find('\\n',To_Pay.find(':',To_Pay.find('Expense')))].strip()\n",
        "              except:\n",
        "                   Living_Expense_to_pay = To_Pay[To_Pay.find(':',To_Pay.find('Liv'))+1:To_Pay.find('\\n',To_Pay.find('Liv'))].strip()\n",
        "\n",
        "              data = [[program_id, uinversity, program,level, language, start_date,tuition,accomodation, living, tuition_to_pay, orig_tuition,accomodation_to_pay,Living_Expense_to_pay,universities_logo]]\n",
        "              program_id+=1\n",
        "              a.writerows(data)\n",
        "\n",
        "print(\"Done\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hoUNLUOa7tw",
        "outputId": "b64ec175-551d-4355-ffd3-7f4af5597584"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dowload the csv file\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"test_new.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z09oZlNF8Z3Z",
        "outputId": "1bb8a190-fe63-48e9-8f5c-c17ef0e661e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0eecde40-98a5-418c-8e22-b4ae96e0248c\", \"test_new.csv\", 135340)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}